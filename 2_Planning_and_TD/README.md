## Planning and Temporal Abstraction
### [Assignment 2 for comp767: Reinforcement Learning](https://docs.google.com/document/d/1yh3Qgcf7f3mkPLzW8j5coJDsd3sXdDKekzpUHMTgnF4/edit#).

#### Track 1 : Dyna-Q (experimental)   
Implement Dyna-Q and reproduce the blocking maze and shortcut maze experiments (see page 135, 136 in Sutton & Barto) in Pycolab. Here’s [a snippet of code](https://colab.research.google.com/drive/14Ov5IHxKcbYRjFKJI04r2wuxTQ8dNIBJ) to show you how to get Pycolab running under colab (yes, they both use the “colab” in their names but as far as I know, they don’t have anything to do with each other).    

#### Kudos/nice if but not required: write a Gym environment wrapper around Pycolab (because their API isn’t very nice).    

#### Read about [Lin’s experience replay](https://link.springer.com/content/pdf/10.1007%2FBF00992699.pdf). How is the above deterministic model update in Dyna-Q related to experience replay? 

colab link:
<https://colab.research.google.com/drive/10W_ZknNnwg93MoFfJlAnnSbm7Oz6q_hU#scrollTo=XSSJks7I7LEN>

Jianing Sun   260791202