{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mandatory Questions\n",
    "### 1.1 Bellman Optimality Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a contraction argument, show that there exists a solution to the Bellman optimality equations. That is : show that the Bellman optimality operator is a contraction mapping. (nonlinear case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellman Operators: <br /> define $T^{\\pi}: \\mathbb{R}^{\\mathcal{S}\\times{\\mathcal{A}}}$ and $T^{*}: \\mathbb{R}^{\\mathcal{S}\\times{\\mathcal{A}}}$ as follows: <br />\n",
    "$T^{\\pi}Q(s,a) = r(s,a)+\\gamma \\sum_{s^{'}}\\mathcal{P}(s^{'}|s,a)V_{\\pi}(s^{'}) \\hspace{1cm} (s,a)\\in \\mathcal{S}\\times{\\mathcal{A}}$ <br \\>\n",
    "$T^{*}Q(s,a) = \\max_{a}\\big|r(s,a)+\\gamma \\sum_{s^{'}}\\mathcal{P}(s^{'}|s,a)V_{\\pi}(s^{'})\\big| \\hspace{1cm} (s,a)\\in \\mathcal{S}\\times{\\mathcal{A}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof: Consider the following statement<br />\n",
    "$$|\\max_{z}f(z)-\\max_{z}h(z)|\\leq \\max_{z}|f(z)-h(z)|$$\n",
    "Applying this to $TV(s)$ we have:<br />\n",
    "$TV_{k+1}(s)-TV_{*}(s) =\\max_{a}\\big|r(s,a)+\\gamma\\sum_{s^{'}}\\mathcal{p}(s^{'}|s,a)V_k(s^{'})\\big|-\\max_{a}\\big|r(s,a)+\\gamma\\sum_{s^{'}}\\mathcal{p}(s^{'}|s,a)V_{*}(s^{'})\\big| $ <br />\n",
    "$\\hspace{3.4cm} \\leq \\max_{a}\\big|\\gamma\\sum_{s^{'}}\\mathcal{p}(s^{'}|s,a)V_k(s^{'})-\\gamma\\sum_{s^{'}}\\mathcal{p}(s^{'}|s,a)V_k(s^{*})\\big|$<br />\n",
    "$\\hspace{3.4cm}\\leq \\max_{a}\\gamma\\big|\\sum_{s^{'}}\\mathcal{p}(s^{'}|s,a)(V_k(s^{'})-V_*(s^{'})\\big|$<br />\n",
    "$\\hspace{3.4cm}\\leq \\gamma\\max_{a}\\big|V_k(s^{'}-V_*(s^{'})\\big|$<br />\n",
    "$\\hspace{3.4cm}=\\gamma \\big|\\big|V_k(s)-V_*(s^{'})\\big|\\big|_\\infty$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, $TV_{k+1}(s)-TV_{*}(s) \\leq \\gamma^{k}||V_0(s)-V_*(s^{'})||$, giving the geometric convergence as $0< \\gamma <1$ <br />\n",
    "Now we show that the nonlinear Bellman operator T is contraction mapping with respect to the maximum num."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Policy Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the values of two successive policies generated by policy iteration are nondecreasing. Assume a finite MDP and conclude (explain why) that policy iteration must terminate under a finite number of steps. Finally, show that upon termination, policy iteration must have found an optimal policy (ie. one which satisfies the optimality equations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Monotonicity of Bellman Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to prove $V(s)\\leq V^{'}(s),\\forall s\\in \\mathcal{S} \\Rightarrow TV(s) \\leq TV^{'}(s), \\forall s \\in \\mathcal{S}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof: Insert into $TV(s)$,<br />\n",
    "$TV(s) = \\max_{a}\\big|r(s,a)+\\gamma\\sum_{s^{'}}\\mathcal{P}(s^{'}|s,a)V(s^{'})\\big|$ <br />\n",
    "$\\hspace{1.17cm}= r(s,a_{V}^{*})+\\gamma \\sum_{s^{'}}\\mathcal{P}(s^{'}|s,a_{V}^{*})V(s^{'})$ <br />\n",
    "$\\hspace{1.17cm}\\leq r(s,a_{V^{'}}^{*})+\\gamma \\sum_{s^{'}}\\mathcal{P}(s^{'}|s,a_{V^{'}}^{*})V(s^{'})$ <br />\n",
    "$\\hspace{1.17cm}\\leq r(s,a_{V^{'}}^{*})+\\gamma \\sum_{s^{'}}\\mathcal{P}(s^{'}|s,a_{V^{'}}^{*})V^{'}(s^{'})$<br />\n",
    "$\\hspace{1.17cm} = TV^{'}(s)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we show that if $V(s)\\leq V^{'}(s),\\forall s\\in \\mathcal{S}$ then $TV(s) \\leq TV^{'}(s), \\forall s \\in \\mathcal{S}$. Which means the values of twoo successive policies generated by policy iteration are nondecreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Reason of termination after a finite number of steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when state and policy are finite, the problem becomes a deterministic shortest path problem with nonnegative arc lengths. If all cycles of the state transition graph have positive length, all policies $\\pi$ that do not terminate from a state $s \\in \\mathcal{S}$ must satisfy $V_{\\pi}(s) = \\infty$, implying that there exists a final policy that terminates from all $s \\in \\mathcal{S}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Proof of optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof: denote $V_{t}^{*} = T_{t}(V_{t+1}^{*})$, $V_{t}^{\\pi} \\leq T_{t}(V_{t+1}^{\\pi})$, and $V_{T}^{*}=V_{T}^{\\pi}$ <br />\n",
    "$\\hspace{2.3cm}V_{t}^{\\pi} \\leq T_{t}(V_{t+1}^{\\pi})$ <br />\n",
    "$\\hspace{3.0cm}\\leq T_{t}T_{t+1}(V_{t+2}^{\\pi})$ <br />\n",
    "$\\hspace{3.0cm}$.<br />\n",
    "$\\hspace{3.0cm}$.<br />\n",
    "$\\hspace{3.0cm}$.<br />\n",
    "$\\hspace{3.0cm}\\leq T_{t}T_{t+1}...T_{T-1}(V_{T}^{\\pi})$ <br />\n",
    "$\\hspace{3.0cm}=T_{t}T_{t+1}...T_{T-1}(V_{T}^{*})$ <br />\n",
    "$\\hspace{3.0cm}=V_{t}^{*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, any policy defined by dynamic programming is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
